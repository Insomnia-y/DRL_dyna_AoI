## 二月实验

- [x] 【2.11上午 固定QoS】

机器：75

```sh
# !/bin/sh
source activate yyx_ishen
group='tune-env-fixedsnr-0211'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
for snr in 100 200 300 400;
do
nohup python -u main_DPPO.py --group ${group} --use_fixed_range --snr ${snr} --device cuda:7 >> ${nohup_dir}/0211.log 2>&1 &
done
```

- [x] 【2.11上午 dynaQoS】

机器：75

```sh
# !/bin/sh
source activate yyx_ishen
group='tune-env-dynaQoS-0211'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
for dyna_level in 1 2 3;
do
nohup python -u main_DPPO.py --group ${group} --dyna_level ${dyna_level} --device cuda:6 >> ${nohup_dir}/0211.log 2>&1 &
done
```

- [x] 【2.11下午 future_obs为0、1、2的实验，DPPO】

每添加一步future_obs，状态维度就增加99。加之前的状态维度是238，因此加2步顶天了~

机器：75

环境：dyna_level=2默认值

```sh
# !/bin/sh
source activate yyx_ishen
group='futureobs-0211'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
for future_obs in 0 1 2;
do
nohup python -u main_DPPO.py --group ${group} --future_obs ${future_obs} --device cuda:4 >> ${nohup_dir}/0211.log 2>&1 &
done
```

- [x] 【2.11下午 继续调难环境的data_amount和update_num】

```sh
# !/bin/sh
source activate yyx_ishen
group='tune-env-0211'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
for user_data_amount in 1 5 10;  # 可以只提高user_data_amount，但不能只降低update_num
do
for update_num in 10 5;
do
if [ $update_num == 10 ]
then device="cuda:3"
else
device="cuda:4"
fi
nohup python -u main_DPPO.py --group ${group} --user_data_amount ${user_data_amount} --update_num ${update_num} --device ${device} >> ${nohup_dir}/0211.log 2>&1 &
done
done
```

- [x] 【2.12凌晨 各算法】

```sh
# !/bin/sh
source activate yyx_ishen
group='baselines-0212'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
for algo in DPPO DMPO CPPO IA2C IC3Net;
do
nohup python -u main_DPPO.py --group ${group} --device cuda:5 >> ${nohup_dir}/0212.log 2>&1 &
done
```



- [x] 【2.12下午 向量化后的DPPO 选择合适的进程数】

```sh
# !/bin/sh
source activate yyx_ishen
group='vec-try-0212'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
for n_thread in 4 8 16;
do
nohup python -u main_DPPO.py --group ${group} --n_thread ${n_thread} --device cuda:6 >> ${nohup_dir}/0212.log 2>&1 &
done
```



- [ ] 【2.12下午 DPPO中扩展值函数的ablation】

```sh
# !/bin/sh
source activate yyx_ishen
group='extendV-ablation-0212'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
nohup python -u main_DPPO.py --group ${group} --n_thread 4 --device cuda:6 >> ${nohup_dir}/0212.log 2>&1 &
nohup python -u main_DPPO.py --group ${group} --n_thread 4 --use-extended-value --device cuda:6 >> ${nohup_dir}/0212.log 2>&1 &  # 这个实验wandb没有打点，已经在tmux重新做
```





- [ ] 【2.12晚上 DMPO 比较model使用GCN和yyx实现的最简单的mlp】

```sh
# !/bin/sh
source activate yyx_ishen
group='dmpo-mlp-0212'
nohup_dir='../nohup_log'
mkdir -p ${nohup_dir}
nohup python -u main_DPPO.py --algo DMPO --group ${group} --n_thread 4 --use-mlp-model --device cuda:3 >> ${nohup_dir}/0212.log 2>&1 &
nohup python -u main_DPPO.py --algo DMPO --group ${group} --n_thread 4 --device cuda:3 >> ${nohup_dir}/0212.log 2>&1 &
```

【2.13中午 重新做以上实验， 并加一个multi-branch】

> DMPO 验证实验后期会出现nan
>
> DMPO --use-mlp-model根本没优化model，为什么效果反而好。。

```sh
python main_DPPO.py --algo DMPO --group 'dmpo-mlp-0212' --n_thread 4 --use-mlp-model --multi-branch --device cuda:3
```



